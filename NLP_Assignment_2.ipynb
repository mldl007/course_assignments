{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9b51269-ed01-4543-ac4e-ba1d0f9060c4",
   "metadata": {},
   "source": [
    "<h4>1. What are Corpora?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71ccb53-c67a-4adc-a431-931a19a8a92d",
   "metadata": {},
   "source": [
    "Corpora is a collection of text documents. For example, a data frame containing sentences to classify may be considered to be a corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83df050-92cb-43ed-9781-ec3c2d54bd0d",
   "metadata": {},
   "source": [
    "<h4>2. What are Tokens?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdd0a96-22fc-41d9-a668-24ab7b6ab468",
   "metadata": {},
   "source": [
    "Tokens are the smallest units of a sentence. A sentence is generally split at spaces and punctuations to form tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aea1c3-4d92-4a5f-819e-5ab4f1615b03",
   "metadata": {},
   "source": [
    "<h4>3. What are Unigrams, Bigrams, Trigrams?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f1781f-73a6-467d-8bd5-60919d8b3fd6",
   "metadata": {},
   "source": [
    "Unigramsa are a single token. Bigrams are combination of 2 tokens. trigrams are combination of 3 tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9195e21-d411-4442-83f8-b3522ecc9ef7",
   "metadata": {},
   "source": [
    "<h4>4. How to generate n-grams from text?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7c2479-5b62-46e6-9354-355a7324f8de",
   "metadata": {},
   "source": [
    "We can generate n-grams by combining 'n' tokens in the text and separating them by '_'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a77a098-37a9-49fe-9e4c-d9836df17458",
   "metadata": {},
   "source": [
    "<h4>5. Explain Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494b36ce-e466-4004-87c8-a54fd04ad57e",
   "metadata": {},
   "source": [
    "Lemmatization is the process of finding the root form of a token. Lemmatization is better than stemming a it returns a meaningful root form of a token, unlike stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b501973e-1933-486c-9c5b-301023f55270",
   "metadata": {},
   "source": [
    "<h4>6. Explain Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1400be-31b9-4a35-a97e-7f1c670fc8f7",
   "metadata": {},
   "source": [
    "Like lemmatization, stemming also finds the root form of a token. but the root forms returned may not have a meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f7d6d1-f0bc-445b-8f3f-fc04aaaebea3",
   "metadata": {},
   "source": [
    "<h4>7. Explain Part-of-speech (POS) tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ac4608-3335-47bc-bee9-1401006d26e6",
   "metadata": {},
   "source": [
    "POS tagging is a token based classification technique where each token in a sentence is assigned a part-of-speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dff5617-1aee-432a-8fdf-11c72ae6bbb4",
   "metadata": {},
   "source": [
    "<h4>8. Explain Chunking or shallow parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074dd972-2681-4d03-9e12-b3f1f6044fbd",
   "metadata": {},
   "source": [
    "Chunking is defined as the process of natural language processing used to identify parts of speech and short phrases present in a given sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63288e4-1c2a-45a5-ab9d-d57c52d202d0",
   "metadata": {},
   "source": [
    "<h4>9. Explain Noun Phrase (NP) chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4576a8c5-3dde-4f8e-9d79-7621ae964fd2",
   "metadata": {},
   "source": [
    "NP chunking is a process of extracting phrases from unstructured text, which means analyzing a sentence to identify the constituents(Noun Groups, Verbs, verb groups, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfded9df-622e-4593-9c4b-e5b1a7418bdf",
   "metadata": {},
   "source": [
    "<h4>10. Explain Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92859d36-7e10-462c-ab3f-909bcd0134df",
   "metadata": {},
   "source": [
    "Named entity recognition is a token classificatio technique where each token isclassified into a categroy like person, location, punctuation, date, etc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
